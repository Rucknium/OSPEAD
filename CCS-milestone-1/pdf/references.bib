
@INPROCEEDINGS{Aeeneh2021,
  author={Aeeneh, Sina and Chervinski, Jo&#x00E3;o Ot&#x00E1;vio and Yu, Jiangshan and Zlatanov, Nikola},
  booktitle={2021 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)},
  title={New Attacks on the Untraceability of Transactions in CryptoNote-Style Blockchains},
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={CryptoNote is a privacy-focused blockchain protocol. Currently, more than 10 different cryptocurrencies including Monero, a popular cryptocurrency with a 1-year average market cap of 2 billion USD, have been developed based on the CryptoNote&#x2019;s protocol. CryptoNote obscures the connection between inputs and outputs of a transaction by adding decoy inputs. In this paper, we introduce probabilistic attacks to the untraceability of CryptoNote which substantially degrades the level of privacy of CryptoNote-style blockchains. We analyze the effectiveness of the proposed attacks and derive their error rates.},
  keywords={},
  doi={10.1109/ICBC51069.2021.9461130},
  ISSN={},
  month={May},}



@article{AllmanMatiasRhodes2009,
author = {Elizabeth S. Allman and Catherine Matias and John A. Rhodes},
title = {{Identifiability of parameters in latent structure models with many observed variables}},
volume = {37},
journal = {The Annals of Statistics},
number = {6A},
publisher = {Institute of Mathematical Statistics},
pages = {3099 -- 3132},
abstract = {While hidden class models of various types arise in many statistical applications, it is often difficult to establish the identifiability of their parameters. Focusing on models in which there is some structure of independence of some of the observed variables conditioned on hidden ones, we demonstrate a general approach for establishing identifiability utilizing algebraic arguments. A theorem of J. Kruskal for a simple latent-class model with finite state space lies at the core of our results, though we apply it to a diverse set of models. These include mixtures of both finite and nonparametric product distributions, hidden Markov models and random graph mixture models, and lead to a number of new results and improvements to old ones. In the parametric setting, this approach indicates that for such models, the classical definition of identifiability is typically too strong. Instead generic identifiability holds, which implies that the set of nonidentifiable parameters has measure zero, so that parameter inference is still meaningful. In particular, this sheds light on the properties of finite mixtures of Bernoulli products, which have been used for decades despite being known to have nonidentifiable parameters. In the nonparametric setting, we again obtain identifiability only when certain restrictions are placed on the distributions that are mixed, but we explicitly describe the conditions.},
keywords = {Algebraic statistics, Conditional independence, Contingency table, finite mixture, Identifiability, latent structure, multivariate Bernoulli mixture, nonparametric mixture},
year = {2009},
doi = {10.1214/09-AOS689},
URL = {https://doi.org/10.1214/09-AOS689}
}



@Article{Argiento2020,
  author={Raffaele Argiento and Andrea Cremaschi and Marina Vannucci},
  title={{Hierarchical Normalized Completely Random Measures to Cluster Grouped Data}},
  journal={Journal of the American Statistical Association},
  year=2020,
  volume={115},
  number={529},
  pages={318-333},
  month={January},
  keywords={},
  doi={10.1080/01621459.2019.159},
  abstract={ In this article, we propose a Bayesian nonparametric model for clustering grouped data. We adopt a hierarchical approach: at the highest level, each group of data is modeled according to a mixture, where the mixing distributions are conditionally independent normalized completely random measures (NormCRMs) centered on the same base measure, which is itself a NormCRM. The discreteness of the shared base measure implies that the processes at the data level share the same atoms. This desired feature allows to cluster together observations of different groups. We obtain a representation of the hierarchical clustering model by marginalizing with respect to the infinite dimensional NormCRMs. We investigate the properties of the clustering structure induced by the proposed model and provide theoretical results concerning the distribution of the number of clusters, within and between groups. Furthermore, we offer an interpretation in terms of generalized Chinese restaurant franchise process, which allows for posterior inference under both conjugate and nonconjugate models. We develop algorithms for fully Bayesian inference and assess performances by means of a simulation study and a real-data illustration. Supplementary materials for this article are available online.},
  url={https://ideas.repec.org/a/taf/jnlasa/v115y2020i529p318-333.html}
}

@misc{AriasCastro2021,
  doi = {10.48550/ARXIV.2106.13925},
  url = {https://arxiv.org/abs/2106.13925},
  author = {Arias-Castro, Ery and Jiang, He},
  keywords = {Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences, 62H30},
  title = {Extending the Patra-Sen Approach to Estimating the Background Component in a Two-Component Mixture Model},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@article{Bagui2006,
author = {Bagui, Subhash and Bagui, Sikha and Chatterjee, A. and Mehra, K.},
year = {2006},
month = {07},
pages = {234-251},
title = {Classification with multiple independent measurements under a separate sampling scheme},
volume = {3},
journal = {Statistical Methodology},
doi = {10.1016/j.stamet.2005.10.001}
}



@Article{Bassett2019,
author="Bassett, Robert
and Deride, Julio",
title="Maximum a posteriori estimators as a limit of Bayes estimators",
journal="Mathematical Programming",
year="2019",
month="Mar",
day="01",
volume="174",
number="1",
pages="129--144",
abstract="Maximum a posteriori and Bayes estimators are two common methods of point estimation in Bayesian statistics. It is commonly accepted that maximum a posteriori estimators are a limiting case of Bayes estimators with 0--1 loss. In this paper, we provide a counterexample which shows that in general this claim is false. We then correct the claim that by providing a level-set condition for posterior densities such that the result holds. Since both estimators are defined in terms of optimization problems, the tools of variational analysis find a natural application to Bayesian point estimation.",
issn="1436-4646",
doi="10.1007/s10107-018-1241-0",
url="https://doi.org/10.1007/s10107-018-1241-0"
}





@article{BenagliaJSS2009,
 title={mixtools: An R Package for Analyzing Mixture Models},
 volume={32},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v032i06},
 doi={10.18637/jss.v032.i06},
 abstract={The &amp;lt;b&amp;gt;mixtools&amp;lt;/b&amp;gt; package for &amp;lt;code&amp;gt;R&amp;lt;/code&amp;gt; provides a set of functions for analyzing a variety of finite mixture models. These functions include both traditional methods, such as EM algorithms for univariate and multivariate normal mixtures, and newer methods that reflect some recent research in finite mixture models. In the latter category, &amp;lt;b&amp;gt;mixtools&amp;lt;/b&amp;gt; provides algorithms for estimating parameters in a wide range of different mixture-of-regression contexts, in multinomial mixtures such as those arising from discretizing continuous multivariate data, in nonparametric situations where the multivariate component densities are completely unspecified, and in semiparametric situations such as a univariate location mixture of symmetric but otherwise unspecified densities. Many of the algorithms of the &amp;lt;b&amp;gt;mixtools&amp;lt;/b&amp;gt; package are EM algorithms or are based on EM-like ideas, so this article includes an overview of EM algorithms for finite mixture models.},
 number={6},
 journal={Journal of Statistical Software},
 author={Benaglia, Tatiana and Chauveau, Didier and Hunter, David R. and Young, Derek S.},
 year={2009},
 pages={1-29}
}




@article{Benaglia2009,
author = {Tatiana Benaglia and Didier Chauveau and David R. Hunter},
title = {An EM-Like Algorithm for Semi- and Nonparametric Estimation in Multivariate Mixtures},
journal = {Journal of Computational and Graphical Statistics},
volume = {18},
number = {2},
pages = {505-526},
year  = {2009},
publisher = {Taylor & Francis},
doi = {10.1198/jcgs.2009.07175},

URL = {
        https://doi.org/10.1198/jcgs.2009.07175

},
eprint = {
        https://doi.org/10.1198/jcgs.2009.07175

}
,
    abstract = { We propose an algorithm for nonparametric estimation for finite mixtures of multivariate random vectors that strongly resembles a true EM algorithm. The vectors are assumed to have independent coordinates conditional upon knowing from which mixture component they come, but otherwise their density functions are completely unspecified. Sometimes, the density functions may be partially specified by Euclidean parameters, a case we call semiparametric. Our algorithm is much more flexible and easily applicable than existing algorithms in the literature; it can be extended to any number of mixture components and any number of vector coordinates of the multivariate observations. Thus it may be applied even in situations where the model is not identifiable, so care is called for when using it in situations for which identifiability is difficult to establish conclusively. Our algorithm yields much smaller mean integrated squared errors than an alternative algorithm in a simulation study. In another example using a real dataset, it provides new insights that extend previous analyses. Finally, we present two different variations of our algorithm, one stochastic and one deterministic, and find anecdotal evidence that there is not a great deal of difference between the performance of these two variants. The computer code and data used in this article are available online. }
}






@article{BERGMEIR2012192,
title = {On the use of cross-validation for time series predictor evaluation},
journal = {Information Sciences},
volume = {191},
pages = {192-213},
year = {2012},
note = {Data Mining for Software Trustworthiness},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2011.12.028},
url = {https://www.sciencedirect.com/science/article/pii/S0020025511006773},
author = {Christoph Bergmeir and Jos{\'e} M. Ben{\'i}tez},
keywords = {Cross-validation, Time series, Predictor evaluation, Error measures, Machine learning, Regression},
abstract = {In time series predictor evaluation, we observe that with respect to the model selection procedure there is a gap between evaluation of traditional forecasting procedures, on the one hand, and evaluation of machine learning techniques on the other hand. In traditional forecasting, it is common practice to reserve a part from the end of each time series for testing, and to use the rest of the series for training. Thus it is not made full use of the data, but theoretical problems with respect to temporal evolutionary effects and dependencies within the data as well as practical problems regarding missing values are eliminated. On the other hand, when evaluating machine learning and other regression methods used for time series forecasting, often cross-validation is used for evaluation, paying little attention to the fact that those theoretical problems invalidate the fundamental assumptions of cross-validation. To close this gap and examine the consequences of different model selection procedures in practice, we have developed a rigorous and extensive empirical study. Six different model selection procedures, based on (i) cross-validation and (ii) evaluation using the series’ last part, are used to assess the performance of four machine learning and other regression techniques on synthetic and real-world time series. No practical consequences of the theoretical flaws were found during our study, but the use of cross-validation techniques led to a more robust model selection. To make use of the “best of both worlds”, we suggest that the use of a blocked form of cross-validation for time series evaluation became the standard procedure, thus using all available information and circumventing the theoretical problems.}
}


@article{BERGMEIR201870,
title = {A note on the validity of cross-validation for evaluating autoregressive time series prediction},
journal = {Computational Statistics \& Data Analysis},
volume = {120},
pages = {70-83},
year = {2018},
issn = {0167-9473},
doi = {https://doi.org/10.1016/j.csda.2017.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167947317302384},
author = {Christoph Bergmeir and Rob J. Hyndman and Bonsoo Koo},
keywords = {Cross-validation, Time series, Autoregression},
abstract = {One of the most widely used standard procedures for model evaluation in classification and regression is K-fold cross-validation (CV). However, when it comes to time series forecasting, because of the inherent serial correlation and potential non-stationarity of the data, its application is not straightforward and often replaced by practitioners in favour of an out-of-sample (OOS) evaluation. It is shown that for purely autoregressive models, the use of standard K-fold CV is possible provided the models considered have uncorrelated errors. Such a setup occurs, for example, when the models nest a more appropriate model. This is very common when Machine Learning methods are used for prediction, and where CV can control for overfitting the data. Theoretical insights supporting these arguments are presented, along with a simulation study and a real-world example. It is shown empirically that K-fold CV performs favourably compared to both OOS evaluation and other time-series-specific techniques such as non-dependent cross-validation.}
}



@article{Bonhomme2016,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/24775334},
 abstract = {This paper provides methods to estimate finite mixtures from data with repeated measurements non-parametrically. We present a constructive identification argument and use it to develop simple two-step estimators of the component distributions and all their functionals. We discuss a computationally efficient method for estimation and derive asymptotic theory. Simulation experiments suggest that our theory provides confidence intervals with good coverage in small samples.},
 author = {Stéphane Bonhomme and Koen Jochmans and Jean-Marc Robin},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {1},
 pages = {211--229},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Non-parametric estimation of finite mixtures from repeated measurements},
 volume = {78},
 year = {2016}
}





@book{CasellaBerger2002,
  author = {Casella, George and Berger, Roger L},
  publisher = {Duxbury Pacific Grove, CA},
  title = {Statistical Inference},
  edition = "Second",
  year = 2002
}




@Article{Cerqueira2020,
author="Cerqueira, Vitor and Torgo, Luis and Mozeti{\v{c}}, Igor",
title="Evaluating time series forecasting models: an empirical study on performance estimation methods",
journal="Machine Learning",
year="2020",
month="Nov",
day="01",
volume="109",
number="11",
pages="1997--2028",
abstract="Performance estimation aims at estimating the loss that a predictive model will incur on unseen data. This process is a fundamental stage in any machine learning project. In this paper we study the application of these methods to time series forecasting tasks. For independent and identically distributed data the most common approach is cross-validation. However, the dependency among observations in time series raises some caveats about the most appropriate way to estimate performance in this type of data. Currently, there is no consensual approach. We contribute to the literature by presenting an extensive empirical study which compares different performance estimation methods for time series forecasting tasks. These methods include variants of cross-validation, out-of-sample (holdout), and prequential approaches. Two case studies are analysed: One with 174 real-world time series and another with three synthetic time series. Results show noticeable differences in the performance estimation methods in the two scenarios. In particular, empirical experiments suggest that blocked cross-validation can be applied to stationary time series. However, when the time series are non-stationary, the most accurate estimates are produced by out-of-sample methods, particularly the holdout approach repeated in multiple testing periods.",
issn="1573-0565",
doi="10.1007/s10994-020-05910-7",
url="https://doi.org/10.1007/s10994-020-05910-7"
}



@article{Copas1974,
author = {J. B. Copas},
title = {{On Symmetric Compound Decision Rules for Dichotomies}},
volume = {2},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {199 -- 204},
abstract = {When an admissible symmetric compound decision rule is applied to a sequence of simple hypothesis testing problems, the decisions are shown to exactly reflect the ordering of the component likelihood ratios. This leads to a characterization of admissible procedures which is closely related to the method ordinarily used in constructing compound decision rules. The extension to estimation problems is indicated.},
keywords = {Admissibility, Compound decision problem, likelihood ratios, monotone likelihood ratio, tests of simple hypotheses},
year = {1974},
doi = {10.1214/aos/1176342626},
URL = {https://doi.org/10.1214/aos/1176342626}
}



@TechReport{Creedy2015,
  author={Creedy, John},
  title={{A Note on Computing the Gini Inequality Measure with Weighted Data}},
  year=2015,
  institution={Victoria University of Wellington, Chair in Public Finance},
  type={Working Paper Series},
  url={https://ideas.repec.org/p/vuw/vuwcpf/4235.html},
  number={4235},
  abstract={ This note sets out some basic results regarding calculation of the Gini measure and its standard error in the context of cross-sectional micro-datasets where sample weights are provided for aggregation from sample to population values.},
  keywords={Gini inequality measure; Value judgements; Inequality measures},
}



@book{crowder1990analysis,
  title={Analysis of Repeated Measures},
  author={Crowder, M.J. and Hand, D.J.},
  isbn={9780412318306},
  lccn={90001339},
  series={Chapman \& Hall/CRC Monographs on Statistics \& Applied Probability},
  year={1990},
  publisher={Taylor \& Francis}
}




@article{Deuber2022,
	title = "SoK: Assumptions Underlying Cryptocurrency Deanonymizations",
	volume = "2022",
	number = "3",
	year = "2022",
	URL = "https://petsymposium.org/2022/files/papers/issue3/popets-2022-0091.pdf",
	journal = "Proceedings on Privacy Enhancing Technologies",
	author = "Deuber, Dominic and Ronge, Viktoria and Rueckert, Christian",
	abstract = "In recent years, cryptocurrencies have increasingly been used in cybercrime and have become the key means of payment in darknet marketplaces, partly due to their alleged anonymity. Furthermore, the research attacking the anonymity of even those cryptocurrencies that claim to offer anonymity by design is growing and is being applied by law enforcement agencies in the fight against cybercrime. Their investigative measures require a certain degree of suspicion and it is unclear whether findings resulting from attacks on cryptocurrencies' anonymity can indeed establish that required degree of suspicion. The reason for this is that these attacks are partly based upon uncertain assumptions which are often not properly addressed in the corresponding papers. To close this gap, we extract the assumptions in papers that are attacking Bitcoin, Monero and Zcash, major cryptocurrencies used in darknet markets which have also received the most attention from researchers. We develop a taxonomy to capture the different nature of those assumptions in order to help investigators to better assess whether the required degree of suspicion for specific investigative measures could be established. We found that assumptions based on user behaviour are in general the most unreliable and thus any findings of attacks based on them might not allow for intense investigative measures such as pre-trial detention. We hope to raise awareness of the problem so that in the future there will be fewer unlawful investigations based upon uncertain assumptions and thus fewer human rights violations.",
}



@article{Egger2022,
	title = "On Defeating Graph Analysis of Anonymous Transactions",
	volume = "2022",
	number = "3",
	year = "2022",
	URL = "https://petsymposium.org/2022/files/papers/issue3/popets-2022-0085.pdf",
	journal = "Proceedings on Privacy Enhancing Technologies",
	author = "Egger, Christoph and Lai, Russell W. F. and Ronge, Viktoria and Woo, Ivy K. Y. and Yin, Hoover H. F.",
	abstract = "In a ring-signature-based anonymous cryptocurrency, signers of a transaction are hidden among a set of potential signers, called a ring, whose size is much smaller than the number of all users. The ring-membership relations specified by the sets of transactions thus induce bipartite transaction graphs, whose distribution is in turn induced by the ring sampler underlying the cryptocurrency.Since efficient graph analysis could be performed on transaction graphs to potentially deanonymise signers, it is crucial to understand the resistance of (the transaction graphs induced by) a ring sampler against graph analysis. Of particular interest is the class of partitioning ring samplers. Although previous works showed that they provide almost optimal local anonymity, their resistance against global, e.g. graph-based, attacks were unclear.In this work, we analyse transaction graphs induced by partitioning ring samplers. Specifically, we show (partly analytically and partly empirically) that, somewhat surprisingly, by setting the ring size to be at least logarithmic in the number of users, a graph-analysing adversary is no better than the one that performs random guessing in deanonymisation up to constant factor of 2.",
}




@article{FixHodges1989,
 ISSN = {03067734, 17515823},
 URL = {http://www.jstor.org/stable/1403797},
 author = {Evelyn Fix and J. L. Hodges},
 journal = {International Statistical Review / Revue Internationale de Statistique},
 number = {3},
 pages = {238--247},
 publisher = {[Wiley, International Statistical Institute (ISI)]},
 title = {Discriminatory Analysis. Nonparametric Discrimination: Consistency Properties},
 volume = {57},
 year = {1989}
}



@article{FraleyRaftery2002,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/3085676},
 abstract = {Cluster analysis is the automated search for groups of related observations in a dataset. Most clustering done in practice is based largely on heuristic but intuitively reasonable procedures, and most clustering methods available in commercial software are also of this type. However, there is little systematic guidance associated with these methods for solving important practical questions that arise in cluster analysis, such as how many clusters are there, which clustering method should be used, and how should outliers be handled. We review a general methodology for model-based clustering that provides a principled statistical approach to these issues. We also show that this can be useful for other problems in multivariate analysis, such as discriminant analysis and multivariate density estimation. We give examples from medical diagnosis, minefield detection, cluster recovery from noisy data, and spatial density estimation. Finally, we mention limitations of the methodology and discuss recent developments in model-based clustering for non-Gaussian data, high-dimensional datasets, large datasets, and Bayesian estimation.},
 author = {Chris Fraley and Adrian E. Raftery},
 journal = {Journal of the American Statistical Association},
 number = {458},
 pages = {611--631},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Model-Based Clustering, Discriminant Analysis, and Density Estimation},
 volume = {97},
 year = {2002}
}





@article{Fruhwirth2021,
author = {Sylvia Fr{\"u}hwirth-Schnatter and Gertraud Malsiner-Walli and Bettina Gr{\"u}n},
title = {{Generalized Mixtures of Finite Mixtures and Telescoping Sampling}},
volume = {16},
journal = {Bayesian Analysis},
number = {4},
publisher = {International Society for Bayesian Analysis},
pages = {1279 -- 1307},
abstract = {Within a Bayesian framework, a comprehensive investigation of mixtures of finite mixtures (MFMs), i.e., finite mixtures with a prior on the number of components, is performed. This model class has applications in model-based clustering as well as for semi-parametric density estimation and requires suitable prior specifications and inference methods to exploit its full potential. We contribute by considering a generalized class of MFMs where the hyperparameter γK of a symmetric Dirichlet prior on the weight distribution depends on the number of components. We show that this model class may be regarded as a Bayesian non-parametric mixture outside the class of Gibbs-type priors. We emphasize the distinction between the number of components K of a mixture and the number of clusters K+, i.e., the number of filled components given the data. In the MFM model, K+ is a random variable and its prior depends on the prior on K and on the hyperparameter γK. We employ a flexible prior distribution for the number of components K and derive the corresponding prior on the number of clusters K+ for generalized MFMs. For posterior inference we propose the novel telescoping sampler which allows Bayesian inference for mixtures with arbitrary component distributions without resorting to reversible jump Markov chain Monte Carlo (MCMC) methods. The telescoping sampler explicitly samples the number of components, but otherwise requires only the usual MCMC steps of a finite mixture model. The ease of its application using different component distributions is demonstrated on several data sets.},
keywords = {Bayesian mixtures, Dirichlet process mixtures, Gibbs-type priors, Pitman-Yor process mixtures, reversible jump MCMC, sparse finite mixtures},
year = {2021},
doi = {10.1214/21-BA1294},
URL = {https://doi.org/10.1214/21-BA1294}
}






@article{Hall1981,
author = {Hall, Peter},
title = {On the Non-Parametric Estimation of Mixture Proportions},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
volume = {43},
number = {2},
pages = {147-156},
keywords = {central limit theorem, efficiency, empiric distribution function, mixture proportions, nonparametric estimators},
doi = {https://doi.org/10.1111/j.2517-6161.1981.tb01164.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1981.tb01164.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1981.tb01164.x},
abstract = {Summary Non-parametric estimates of mixing proportions based on kernel-type density estimators are badly suited to several types of data. They suffer from aberrations due to rounding or truncation of the measurements, and their construction involves the crucial choice of the “window size”, or smoothing parameter. In many circumstances estimators based on the empiric distribution function would be more suitable, and in this paper we investigate their properties. The estimators we introduce lead in a natural way to non-parametric forms of well-known parametric estimators. Their efficiency approaches 100 per cent as the distances between the component distributions increase.},
year = {1981}
}




@inproceedings{Hsu2014,
  doi = {10.1109/csf.2014.35},
  url = {https://doi.org/10.1109/csf.2014.35},
  year = {2014},
  month = jul,
  publisher = {{IEEE}},
  author = {Justin Hsu and Marco Gaboardi and Andreas Haeberlen and Sanjeev Khanna and Arjun Narayan and Benjamin C. Pierce and Aaron Roth},
  title = {Differential Privacy: An Economic Method for Choosing Epsilon},
  booktitle = {2014 {IEEE} 27th Computer Security Foundations Symposium}
}



@book{HyndmanAthanasopoulos2021,
  author = {Hyndman, Rob J and Athanasopoulos, George},
  publisher = {OTexts: Melbourne, Australia},
  title = {Forecasting: Principles and Practice},
  edition = "Third",
  year = 2021,
  url = "https://otexts.com/fpp3/"
}




@article{KasaharaShimotsu2014,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/24772747},
 abstract = {We analyse the identifiability of the number of components in k-variate, M-component finite mixture models in which each component distribution has independent marginals, including models in latent class analysis. Without making parametric assumptions on the component distributions, we investigate how one can identify the number of components from the distribution function of the observed data. When k ≥ 2, a lower bound on the number of components (M) is non-parametrically identifiable from the rank of a matrix constructed from the distribution function of the observed variables. Building on this identification condition, we develop a procedure to estimate a lower bound on the number of components consistently.},
 author = {Hiroyuki Kasahara and Katsumi Shimotsu},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {1},
 pages = {97--111},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Non-parametric identification and estimation of the number of components in multivariate mixtures},
 volume = {76},
 year = {2014}
}



@misc{Krawiec-Thayer2021,
	title = "Fingerprinting a flood: forensic statistical analysis of the mid-2021 Monero transaction volume anomaly",
	year = "2021",
	URL = "https://mitchellpkt.medium.com/fingerprinting-a-flood-forensic-statistical-analysis-of-the-mid-2021-monero-transaction-volume-a19cbf41ce60",
	author = "Krawiec-Thayer, Mitchell P. and Neptune and Rucknium and Jberman and Carrington",
	note = "Available at https://mitchellpkt.medium.com/fingerprinting-a-flood-forensic-statistical-analysis-of-the-mid-2021-monero-transaction-volume-a19cbf41ce60"
}



@inproceedings{Kumar2017,
	title = "A Traceability Analysis of Monero's Blockchain",
	year = "2017",
	URL = "https://doi.org/10.1007/978-3-319-66399-9_9",
	booktitle = "European Symposium on Research in Computer Security (ESORICS)",
	author = "Kumar, Amrit and Fischer, Clement and Tople, Shruti and Saxena, Prateek",
	abstract = "Privacy and anonymity are important desiderata in the use of cryptocurrencies. Monero?a privacy centric cryptocurrency has rapidly gained popularity due to its unlinkability and untraceablity guarantees. It has a market capitalization of USD 290M. In this work, we quantify the efficacy of three attacks on Monero?s untraceability guarantee, which promises to make it hard to trace the origin of a received fund, by analyzing its blockchain data. To this end, we develop three attack routines and evaluate them on the Monero blockchain. Our results show that in 88{\%} of cases, the origin of the funds can be easily determined with certainty. Moreover, we have compelling evidence that two of the attack routines also extend to Monero RingCTs?the second generation Monero that even hides the transaction amount. We further observe that over 98{\%} of the results can in fact be obtained by a simple temporal analysis. In light of our findings, we discuss mitigations to strengthen Monero against these attacks.We shared our findings with theMonero development team and the general community. This has resulted into several discussions and proposals for fixes.",
}




@article{KwonMbakop2021,
author = {Caleb Kwon and Eric Mbakop},
title = {{Estimation of the number of components of nonparametric multivariate finite mixture models}},
volume = {49},
journal = {The Annals of Statistics},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {2178 -- 2205},
abstract = {We propose a novel estimator for the number of mixture components (denoted by M) in a nonparametric finite mixture model. The setting that we consider is one where the analyst has repeated observations of K≥2 variables that are conditionally independent given a finitely supported latent variable with M support points. Under a mild assumption on the joint distribution of the observed and latent variables, we show that an integral operator T that is identified from the data has rank equal to M. We use this observation, in conjunction with the fact that singular values of operators are stable under perturbations, to propose an estimator of M, which essentially consists of a thresholding rule that counts the number of singular values of a consistent estimator of T that are greater than a data-driven threshold. We prove that our estimator of M is consistent, and establish nonasymptotic results, which provide finite sample performance guarantees for our estimator. We present a Monte Carlo study, which shows that our estimator performs well for samples of moderate size.},
keywords = {Conditional independence, Finite mixture model, latent model, multivariate data, nonparametric mixture},
year = {2021},
doi = {10.1214/20-AOS2032},
URL = {https://doi.org/10.1214/20-AOS2032}
}



@article{Levine2011,
 ISSN = {00063444, 14643510},
 URL = {http://www.jstor.org/stable/23076159},
 abstract = {We introduce an algorithm for estimating the parameters in a finite mixture of completely unspecified multivariate components in at least three dimensions under the assumption of conditionally independent coordinate dimensions. We prove that this algorithm, based on a majorization-minimization idea, possesses a desirable descent property just as any EM algorithm does. We discuss the similarities between our algorithm and a related one, the so-called nonlinearly smoothed EM algorithm for the non-mixture setting. We also demonstrate via simulation studies that the new algorithm gives very similar results to another algorithm that has been shown empirically to be effective but that does not satisfy any descent property. We provide code for implementing the new algorithm in a publicly available R package.},
 author = {M. Levine and D. R. Hunter and D. Chauveau},
 journal = {Biometrika},
 number = {2},
 pages = {403--416},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Maximum smoothed likelihood for multivariate mixtures},
 volume = {98},
 year = {2011}
}



@article{LilienfeldLandfield2008,
author = {Scott O. Lilienfeld and Kristin Landfield},
title ={Science and Pseudoscience in Law Enforcement: A User-Friendly Primer},
journal = {Criminal Justice and Behavior},
volume = {35},
number = {10},
pages = {1215-1230},
year = {2008},
doi = {10.1177/0093854808321526},

URL = {
        https://doi.org/10.1177/0093854808321526

},
eprint = {
        https://doi.org/10.1177/0093854808321526

}
,
    abstract = { Pseudoscience and questionable science are largely neglected problems in police and other law enforcement work. In this primer, the authors delineate the key differences between science and pseudoscience, presenting 10 probabilistic indicators or warning signs, such as lack of falsifiability, absence of safeguards against confirmation bias, and lack of self-correction, that can help consumers of the police literature to distinguish scientific from pseudoscientific claims. Each of these warning signs is illustrated with an example from law enforcement. By attending to the differences between scientific and pseudoscientific assertions, police officers and other law enforcement officials can minimize their risk of errors and make better real-world decisions. }
}




@article{Liu_2019,
	doi = {10.2478/popets-2019-0045},
	url = {https://doi.org/10.2478%2Fpopets-2019-0045},
	year = 2019,
	month = {jul},
	publisher = {Privacy Enhancing Technologies Symposium Advisory Board},
	volume = {2019},
	number = {3},
	pages = {233--254},
	author = {Changchang Liu and Xi He and Thee Chanyaswad and Shiqiang Wang and Prateek Mittal},
	title = {Investigating Statistical Privacy Frameworks from the Perspective of Hypothesis Testing},
	journal = {Proceedings on Privacy Enhancing Technologies}
}




@misc{Mackenzie2015,
	title = "Improving Obfuscation in the CryptoNote Protocol",
	number = "4",
	year = "2015",
	URL = "https://www.getmonero.org/resources/research-lab/pubs/MRL-0004.pdf",
	booktitle = "Monero Research Lab",
	author = "Mackenzie, Adam and Noether, Surae and Monero Core Team",
	abstract = "We identify several blockchain analysis attacks available to degrade the untraceability of the CryptoNote 2.0 protocol. We analyze possible solutions, discuss the relative merits and drawbacks to those solutions, and recommend improvements to the Monero protocol that will hopefully provide long-term resistance of the cryptocurrency against blockchain analysis. Our recommended improvements to Monero include a protocol-level network-wide minimum mix-in policy of n = 2 foreign outputs per ring signature, a protocol-level increase of this value to n = 4 after two years, and a wallet-level default value of n = 4 in the interim. We also recommend a torrent-style method of sending Monero output. We also discuss a non-uniform, age-dependent mix-in selection method to mitigate the other forms of blockchain analysis identified herein, but we make no formal recommendations on implementation for a variety of reasons. The ramifications following these improvements are also discussed in some detail. This research bulletin has not undergone peer review, and reflects only the results of internal investigation.",
	howpublished = "Research Bulletin",
}





@article{Maji2019,
  doi = {10.1007/s10463-018-0678-5},
  url = {https://doi.org/10.1007/s10463-018-0678-5},
  year = {2019},
  publisher = {Springer Science and Business Media {LLC}},
  volume = {71},
  number = {5},
  pages = {1289--1322},
  author = {Avijit Maji and Abhik Ghosh and Ayanendranath Basu and Leandro Pardo},
  title = {Robust statistical inference based on the C-divergence family},
  journal = {Annals of the Institute of Statistical Mathematics}
}






@techreport{MakarovSchoar2021,
 title = "Blockchain Analysis of the Bitcoin Market",
 author = "Makarov, Igor and Schoar, Antoinette",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "29396",
 year = "2021",
 month = "October",
 doi = {10.3386/w29396},
 URL = "http://www.nber.org/papers/w29396",
 abstract = {In this paper, we provide detailed analyses of the Bitcoin network and its main participants. We build a novel database using a large number of public and proprietary sources to link Bitcoin addresses to real entities and develop an extensive suite of algorithms to extract information about the behavior of the main market participants. We conduct three major pieces of analysis of the Bitcoin eco-system. First, we analyze the transaction volume and network structure of the main participants on the blockchain. Second, we document the concentration and regional composition of the miners which are the backbone of the verification protocol and ensure the integrity of the blockchain ledger. Finally, we analyze the ownership concentration of the largest holders of Bitcoin.},
}




@article{MAKRIDAKIS2022,
title = {M5 accuracy competition: Results, findings, and conclusions},
journal = {International Journal of Forecasting},
year = {2022},
issn = {0169-2070},
doi = {https://doi.org/10.1016/j.ijforecast.2021.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0169207021001874},
author = {Spyros Makridakis and Evangelos Spiliotis and Vassilios Assimakopoulos},
keywords = {Forecasting competitions, M competitions, Accuracy, Time series, Machine learning, Retail sales forecasting},
abstract = {In this study, we present the results of the M5 “Accuracy” competition, which was the first of two parallel challenges in the latest M competition with the aim of advancing the theory and practice of forecasting. The main objective in the M5 “Accuracy” competition was to accurately predict 42,840 time series representing the hierarchical unit sales for the largest retail company in the world by revenue, Walmart. The competition required the submission of 30,490 point forecasts for the lowest cross-sectional aggregation level of the data, which could then be summed up accordingly to estimate forecasts for the remaining upward levels. We provide details of the implementation of the M5 “Accuracy” challenge, as well as the results and best performing methods, and summarize the major findings and conclusions. Finally, we discuss the implications of these findings and suggest directions for future research.}
}




@article{malsiner2017identifying,
  title={Identifying mixtures of mixtures using Bayesian estimation},
  author={Malsiner-Walli, Gertraud and Fr{\"u}hwirth-Schnatter, Sylvia and Gr{\"u}n, Bettina},
  journal={Journal of Computational and Graphical Statistics},
  volume={26},
  number={2},
  pages={285--295},
  year={2017},
  publisher={Taylor \& Francis},
  URL = {https://www.tandfonline.com/doi/full/10.1080/10618600.2016.1200472}
}




@misc{Mbakop2017IdentificationOA,
  title = {Identification of auctions with incomplete bid data in the presence of unobserved heterogeneity},
  author = {Eric D. Mbakop},
  year = {2017},
  howpublished = "Working Papers, Univ. Calgary",
  URL = {https://cpb-us-e1.wpmucdn.com/sites.northwestern.edu/dist/5/1999/files/2017/10/JMP-Brouillon-1bom42o.pdf}
}



@book{mclachlan1992discriminant,
  title={Discriminant Analysis and Statistical Pattern Recognition},
  author={McLachlan, G.},
  isbn={9780471615316},
  series={Wiley Series in Probability and Statistics},
  year={1992},
  publisher={Wiley}
}



@book{mclachlan2000finite,
  title={Finite Mixture Models},
  author={McLachlan, G. and Peel, D.},
  isbn={9780471006268},
  lccn={00043324},
  series={Wiley Series in Probability and Statistics},
  year={2000},
  publisher={Wiley}
}




@article{McLachlan2019,
author = {McLachlan, Geoffrey J. and Lee, Sharon X. and Rathnayake, Suren I.},
title = {Finite Mixture Models},
journal = {Annual Review of Statistics and Its Application},
volume = {6},
number = {1},
pages = {355-378},
year = {2019},
doi = {10.1146/annurev-statistics-031017-100325},

URL = {
        https://doi.org/10.1146/annurev-statistics-031017-100325

},
eprint = {
        https://doi.org/10.1146/annurev-statistics-031017-100325

}
,
    abstract = { The important role of finite mixture models in the statistical analysis of data is underscored by the ever-increasing rate at which articles on mixture applications appear in the statistical and general scientific literature. The aim of this article is to provide an up-to-date account of the theory and methodological developments underlying the applications of finite mixture models. Because of their flexibility, mixture models are being increasingly exploited as a convenient, semiparametric way in which to model unknown distributional shapes. This is in addition to their obvious applications where there is group-structure in the data or where the aim is to explore the data for such structure, as in a cluster analysis. It has now been three decades since the publication of the monograph by McLachlan \& Basford (1988) with an emphasis on the potential usefulness of mixture models for inference and clustering. Since then, mixture models have attracted the interest of many researchers and have found many new and interesting fields of application. Thus, the literature on mixture models has expanded enormously, and as a consequence, the bibliography here can only provide selected coverage. }
}




@unpublished{milhaud:hal-03201760,
  TITLE = {{Shape constraint free two-sample contamination model testing}},
  AUTHOR = {Milhaud, Xavier and Pommeret, Denys and Salhi, Yahia and Vandekerkhove, Pierre},
  URL = {https://hal.archives-ouvertes.fr/hal-03201760},
  NOTE = {working paper or preprint},
  YEAR = {2021},
  MONTH = Apr,
  KEYWORDS = {finite mixture model ; semiparametric estimation ; Cram{\'e}r-von Mises ; mortality},
  PDF = {https://hal.archives-ouvertes.fr/hal-03201760/file/2021-04-19-TwoSample-CVM-test.pdf},
  HAL_ID = {hal-03201760},
  HAL_VERSION = {v1},
}





@article{2018,
	title = "An Empirical Analysis of Traceability in the Monero Blockchain",
	DOI = "doi:10.1515/popets-2018-0025",
	volume = "2018",
	number = "3",
	year = "2018",
	URL = "https://doi.org/10.1515/popets-2018-0025",
	journal = "Proceedings on Privacy Enhancing Technologies",
	pages = "143--163",
	author = "M{\"o}ser, Malte and Soska, Kyle and Heilman, Ethan and Lee, Kevin and Heffan, Henry and Srivastava, Shashvat and Hogan, Kyle and Hennessey, Jason and Miller, Andrew and Narayanan, Arvind and Christin, Nicolas",
	abstract = "Monero is a privacy-centric cryptocurrency that allows users to obscure their transactions by including chaff coins, called ?mixins,? along with the actual coins they spend. In this paper, we empirically evaluate two weaknesses in Monero?s mixin sampling strategy. First, about 62{\%} of transaction inputs with one or more mixins are vulnerable to ?chain-reaction? analysis - that is, the real input can be deduced by elimination. Second, Monero mixins are sampled in such a way that they can be easily distinguished from the real coins by their age distribution; in short, the real input is usually the ?newest? input. We estimate that this heuristic can be used to guess the real input with 80{\%} accuracy over all transactions with 1 or more mixins. Next, we turn to the Monero ecosystem and study the importance of mining pools and the former anonymous marketplace AlphaBay on the transaction volume. We find that after removing mining pool activity, there remains a large amount of potentially privacy-sensitive transactions that are affected by these weaknesses. We propose and evaluate two countermeasures that can improve the privacy of future transactions.",
}




@article{Murphy1985,
author = { Kevin M.   Murphy  and  Robert H.   Topel },
title = {Estimation and Inference in Two-Step Econometric Models},
journal = {Journal of Business \& Economic Statistics},
volume = {3},
number = {4},
pages = {370-379},
year  = {1985},
publisher = {Taylor & Francis},
doi = {10.1080/07350015.1985.10509471},

URL = {
        https://www.tandfonline.com/doi/abs/10.1080/07350015.1985.10509471

},
eprint = {
        https://www.tandfonline.com/doi/pdf/10.1080/07350015.1985.10509471

}
,
    abstract = { A commonly used procedure in a wide class of empirical applications is to impute unobserved regressors, such as expectations, from an auxiliary econometric model. This two-step (T-S) procedure fails to account for the fact that imputed regressors are measured with sampling error, so hypothesis tests based on the estimated covariance matrix of the second-step estimator are biased, even in large samples. We present a simple yet general method of calculating asymptotically correct standard errors in T-S models. The procedure may be applied even when joint estimation methods, such as full information maximum likelihood, are inappropriate or computationally infeasible. We present two examples from recent empirical literature in which these corrections have a major impact on hypothesis testing. }
}




@article{newton1996bootstrapping,
  title={Bootstrapping phytogenies: Large deviations and dispersion effects},
  author={Newton, Michael A},
  journal={Biometrika},
  volume={83},
  number={2},
  pages={315--328},
  year={1996},
  publisher={Oxford University Press},
  URL = {https://www.jstor.org/stable/2337603}
}




@incollection{Ni2021,
	title = "When the Recursive Diversity Anonymity Meets the Ring Signature",
	ISBN = "9781450383431",
	year = "2021",
	URL = "https://doi.org/10.1145/3448016.3452825",
	booktitle = "Proceedings of the 2021 International Conference on Management of Data",
	pages = "1359?1371",
	author = "Ni, Wangze and Cheng, Peng and Chen, Lei and Lin, Xuemin",
	abstract = "In privacy-preserving blockchain systems, to protect a sender's identity of a transaction in privacy-preserving blockchain systems, ring signature (RS) schemes have been widely implemented, which allow users to obscure consumed tokens via including {"}mixin'' (i.e., chaff tokens). However, recent works point out that existing RS schemes are vulnerable to the {"}chain-reaction'' analysis, where adversaries eliminate mixins of RSs by utilizing the fact that each token can only be consumed in a RS. By {"}chain-reaction'' analysis, adversaries can find some definite token-RS pair sets (DTRSs) to confirm the sender's identity of a RS. Besides, the existing RS schemes do not consider the diversity of mixins when generating a RS. Moreover, since the transaction fee is proportional to the number of mixins, a use is motivated to use a RS with the minimum number of mixins. In this paper, we formally define the diversity-aware mixins selection (DA-MS) problem, which aims to generate a RS with the minimum number of mixins satisfying the constraints of its diversity and the anonymity of other RSs. We prove the DA-MS problem is ${\#}P$ and propose a breadth-first search algorithm to get the optimal solution. Furthermore, to efficiently solve the DA-MS problem, we propose two practical configurations and two approximation algorithms with theoretic guarantees. Through comprehensive experiments on real data sets as well as synthetic data sets, we illustrate the effectiveness and the efficiency of our solutions.",
	publisher = "Association for Computing Machinery",
	address = "New York, NY, USA",
}




@article{ohagan2012computational,
  title={Computational aspects of fitting mixture models via the expectation--maximization algorithm},
  author={O'Hagan, Adrian and Murphy, Thomas Brendan and Gormley, Isobel Claire},
  journal={Computational Statistics \& Data Analysis},
  volume={56},
  number={12},
  pages={3843--3864},
  year={2012},
  publisher={Elsevier},
  URL = {https://www.sciencedirect.com/science/article/pii/S0167947312002101}
}




@article{Patra2016,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/24775367},
 abstract = {We consider a two-component mixture model with one known component. We develop methods for estimating the mixing proportion and the unknown distribution non-parametrically, given independent and identically distributed data from the mixture model, using ideas from shape-restricted function estimation. We establish the consistency of our estimators. We find the rate of convergence and asymptotic limit of the estimator for the mixing proportion. Completely automated distribution-free honest finite sample lower confidence bounds are developed for the mixing proportion. Connection to the problem of multiple testing is discussed. The identifiability of the model and the estimation of the density of the unknown distribution are also addressed. We compare the estimators proposed, which are easily implementable, with some of the existing procedures through simulation studies and analyse two data sets: one arising from an application in astronomy and the other from a microarray experiment.},
 author = {Rohit Kumar Patra and Bodhisattva Sen},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {4},
 pages = {869--893},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Estimation of a two-component mixture model with applications to multiple testing},
 volume = {78},
 year = {2016}
}



@article{ReedJorgensen2004,
author = { William J.   Reed  and  Murray   Jorgensen },
title = {The Double Pareto-Lognormal Distribution---A New Parametric Model for Size Distributions},
journal = {Communications in Statistics - Theory and Methods},
volume = {33},
number = {8},
pages = {1733-1753},
year  = {2004},
publisher = {Taylor & Francis},
doi = {10.1081/STA-120037438},

URL = {
        https://doi.org/10.1081/STA-120037438

},
eprint = {
        https://doi.org/10.1081/STA-120037438

}
,
    abstract = { Abstract A family of probability densities, which has proved useful in modelling the size distributions of various phenomens, including incomes and earnings, human settlement sizes, oil-field volumes and particle sizes, is introduced. The distribution, named herein as the double Pareto-lognormal or dPlN distribution, arises as that of the state of a geometric Brownian motion (GBM), with lognormally distributed initial state, after an exponentially distributed length of time (or equivalently as the distribution of the killed state of such a GBM with constant killing rate). A number of phenomena can be viewed as resulting from such a process (e.g., incomes, settlement sizes), which explains the good fit. Properties of the distribution are derived and estimation methods discussed. The distribution exhibits Paretian power-law) behaviour in both tails, and when plotted on logarithmic axes, its density exhibits hyperbolic-type behaviour. }
}



@article{ritchie2020consistent,
  title={Consistent estimation of identifiable nonparametric mixture models from grouped observations},
  author={Ritchie, Alexander and Vandermeulen, Robert A and Scott, Clayton},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11676--11686},
  year={2020},
  URL = {https://papers.nips.cc/paper/2020/hash/866d90e0921ac7b024b47d672445a086-Abstract.html}
}



@article{Ronge2021,
	title = "Foundations of Ring Sampling",
	DOI = "doi:10.2478/popets-2021-0047",
	volume = "2021",
	number = "3",
	year = "2021",
	URL = "https://doi.org/10.2478/popets-2021-0047",
	journal = "Proceedings on Privacy Enhancing Technologies",
	pages = "265--288",
	author = "Ronge, Viktoria and Egger, Christoph and Lai, Russell W. F. and Schr{\"o}der, Dominique and Yin, Hoover H. F.",
	abstract = "A ring signature scheme allows the signer to sign on behalf of an ad hoc set of users, called a ring. The verifier can be convinced that a ring member signs, but cannot point to the exact signer. Ring signatures have become increasingly important today with their deployment in anonymous cryptocurrencies. Conventionally, it is implicitly assumed that all ring members are equally likely to be the signer. This assumption is generally false in reality, leading to various practical and devastating deanonymizing attacks in Monero, one of the largest anonymous cryptocurrencies. These attacks highlight the unsatisfactory situation that how a ring should be chosen is poorly understood.We propose an analytical model of ring samplers towards a deeper understanding of them through systematic studies. Our model helps to describe how anonymous a ring sampler is with respect to a given signer distribution as an information-theoretic measure. We show that this measure is robust ? it only varies slightly when the signer distribution varies slightly. We then analyze three natural samplers ? uniform, mimicking, and partitioning ? under our model with respect to a family of signer distributions modeled after empirical Bitcoin data. We hope that our work paves the way towards researching ring samplers from a theoretical point of view.",
}




@article{VandermeulenScott2019,
author = {Robert A. Vandermeulen and Clayton D. Scott},
title = {{An operator theoretic approach to nonparametric mixture models}},
volume = {47},
journal = {The Annals of Statistics},
number = {5},
publisher = {Institute of Mathematical Statistics},
pages = {2704 -- 2733},
abstract = {When estimating finite mixture models, it is common to make assumptions on the mixture components, such as parametric assumptions. In this work, we make no distributional assumptions on the mixture components and instead assume that observations from the mixture model are grouped, such that observations in the same group are known to be drawn from the same mixture component. We precisely characterize the number of observations $n$ per group needed for the mixture model to be identifiable, as a function of the number $m$ of mixture components. In addition to our assumption-free analysis, we also study the settings where the mixture components are either linearly independent or jointly irreducible. Furthermore, our analysis considers two kinds of identifiability, where the mixture model is the simplest one explaining the data, and where it is the only one. As an application of these results, we precisely characterize identifiability of multinomial mixture models. Our analysis relies on an operator-theoretic framework that associates mixture models in the grouped-sample setting with certain infinite-dimensional tensors. Based on this framework, we introduce a general spectral algorithm for recovering the mixture components.},
keywords = {Identifiability, joint irreducibility, mixture model, multinomial mixture, nonparametric mixture, tensor factorization, topic model},
year = {2019},
doi = {10.1214/18-AOS1762},
URL = {https://doi.org/10.1214/18-AOS1762}
}




@InProceedings{Vankadara2021,
  title = 	 { Recovery Guarantees for Kernel-based Clustering under Non-parametric Mixture Models },
  author =       {Vankadara, Leena C. and Bordt, Sebastian and von Luxburg, Ulrike and Ghoshdastidar, Debarghya},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3817--3825},
  year = 	 {2021},
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 {130},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v130/vankadara21a/vankadara21a.pdf},
  url = 	 {https://proceedings.mlr.press/v130/vankadara21a.html},
  abstract = 	 { Despite the ubiquity of kernel-based clustering, surprisingly few statistical guarantees exist beyond settings that consider strong structural assumptions on the data generation process. In this work, we take a step towards bridging this gap by studying the statistical performance of kernel-based clustering algorithms under non-parametric mixture models. We provide necessary and sufficient separability conditions under which these algorithms can consistently recover the underlying true clustering. Our analysis provides guarantees for kernel clustering approaches without structural assumptions on the form of the component distributions. Additionally, we establish a key equivalence between kernel-based data-clustering and kernel density-based clustering. This enables us to provide consistency guarantees for kernel-based estimators of non-parametric mixture models. Along with theoretical implications, this connection could have practical implications, including in the systematic choice of the bandwidth of the Gaussian kernel in the context of clustering. }
}




@misc{Vijayakumaran2021,
	title = "Analysis of CryptoNote Transaction Graphs using the Dulmage-Mendelsohn Decomposition",
	year = "2021",
	URL = "https://eprint.iacr.org/2021/760",
	author = "Vijayakumaran, Saravanan",
	abstract = "Transactions in CryptoNote blockchains use linkable ring signatures to prevent double spending. Each transaction ring is associated with a key image, which is a collision-resistant one-way function of the spent output's secret key. Several techniques have been proposed to trace CryptoNote transactions, i.e. identify the actual output associated with a key image, by using the transaction history. In this paper, we show that the Dulmage-Mendelsohn (DM) decomposition of bipartite graphs can be used to trace CryptoNote transactions. The DM decomposition technique is optimal in the sense that it eliminates every output-key image association which is incompatible with the transaction history.We used the Monero transaction history for performance comparison. For pre-RingCT outputs in Monero, the DM decomposition technique performs better than existing techniques. For RingCT outputs in Monero, the DM decomposition technique has the same performance as existing techniques, with only five out of approximately 29 million outputs being identified as spent. To study the effect of hard forks on Monero RingCT output traceability, we used information from four Monero hard forks. The DM decomposition technique is able to trace only 62,809 out of approximately 26 million RingCT transaction rings. Our results are further evidence supporting the claim that Monero RingCT transactions are mostly immune to traceability attacks.",
	howpublished = "Cryptology ePrint Archive, Report 2021/760",
}


@article{WeiNguyendeFinetti2022,
author = {Yun Wei and XuanLong Nguyen},
title = {{Convergence of de Finetti's mixing measure in latent structure models for observed exchangeable sequences}},
volume = {50},
journal = {The Annals of Statistics},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {1859 -- 1889},
abstract = {Mixtures of product distributions are a powerful device for learning about heterogeneity within data populations. In this class of latent structure models, de Finetti's mixing measure plays the central role for describing the uncertainty about the latent parameters representing heterogeneity. In this paper, posterior contraction theorems for de Finetti's mixing measure arising from finite mixtures of product distributions will be established; under the setting the number of exchangeable sequences of observed variables increases while sequence length(s) may be either fixed or varied. The role of both the number of sequences and the sequence lengths will be carefully examined. In order to obtain concrete rates of convergence, a first-order identifiability theory for finite mixture models and a family of sharp inverse bounds for mixtures of product distributions will be developed via a harmonic analysis of such latent structure models. This theory is applicable to broad classes of probability kernels composing the mixture model of product distributions for both continuous and discrete domain X. Examples of interest include the case the probability kernel is only weakly identifiable in the sense of (Ann. Statist. 44 (2016) 2726–2755), the case where the kernel is itself a mixture distribution as in hierarchical models, and the case the kernel may not have a density with respect to a dominating measure on an abstract domain X, such as Dirichlet processes.},
keywords = {Fourier analysis, hierarchical models, inverse bounds, mixture of product distributions, mixtures of grouped observations, mixtures of repeated measurements},
year = {2022},
doi = {10.1214/21-AOS2120},
URL = {https://doi.org/10.1214/21-AOS2120}
}



@misc{Ye2020,
	title = "Alt-Coin Traceability",
	year = "2020",
	URL = "https://eprint.iacr.org/2020/593",
	author = "Ye, Claire and Ojukwu, Chinedu and Hsu, Anthony and Hu, Ruiqi",
	abstract = "Many alt-coins developed in recent years make strong privacy guarantees, claiming to be virtually untraceable. This paper explores the extent to which these claims are true after the first appraisals were made about these coins. In particular, we will investigate Monero (XMR) and Zcash (ZEC), competitors in the private cryptocurrency space. We will test how traceable these currencies are after the most recent security updates, and how they hold up against their claims. We run some traceability experiments based on previously published papers for each coin. Results show that, introducing strict security and anonymity requirements into the cryptocurrency ecosystem makes the coin effectively untraceable, as shown by Monero. On the other hand, Zcash still hesitates to introduce changes that alter user behavior. Despite its strong cryptographic features, transactions are overall more traceable.",
	howpublished = "Cryptology ePrint Archive, Report 2020/593",
}




@inproceedings{Yu2019,
	title = "Re-Thinking Untraceability in the CryptoNote-Style Blockchain",
	DOI = "10.1109/CSF.2019.00014",
	year = "2019",
	URL = "https://ieeexplore.ieee.org/document/8823713",
	booktitle = "2019 IEEE 32nd Computer Security Foundations Symposium (CSF)",
	pages = "94--9413",
	author = "Yu, Jiangshan and Au, Man Ho Allen and Esteves-Verissimo, Paulo",
	abstract = "We develop new foundations on transaction untraceability for CryptoNote-style blockchain systems. In particular, we observe new attacks; develop theoretical foundations to model transaction untraceability; provide the least upper bound of transaction untraceability guarantee; provide ways to efficiently and automatically verify whether a given ledger achieves optimal transaction untraceability; and provide a general solution that achieves provably optimal transaction untraceability. Unlike previous cascade effect attacks (ESORICS' 17 and PETS' 18) on CryptoNote-style transaction untraceability, we consider not only a passive attacker but also an active adaptive attacker. Our observed attacks allow both types of attacker to trace blockchain transactions that cannot be traced by using the existing attacks. We develop a series of new games, which we call {"}The Sun-Tzu Survival Problem{"}, to model CryptoNote-style blockchain transaction untraceability and our identified attacks. In addition, we obtain seven novel results, where three of them are negative and the rest are positive. In particular, thanks to our abstract game, we are able to build bipartite graphs to model transaction untraceability, and provide reductions to formally relate the hardness of calculating untraceability to the hardness of calculating the number of perfect matchings in all possible bipartite graphs. We prove that calculating transaction untraceability is a {\#}P-complete problem, which is believed to be even more difficult to solve than NP problems. In addition, we provide the first result on the least upper bound of transaction untraceability. Moreover, through our theoretical results, we are able to provide ways to efficiently and automatically verify whether a given ledger achieves optimal transaction untraceability. Furthermore, we propose a simple strategy for CryptoNote-style blockchain systems to achieve optimal untraceability. We take Monero as a concrete example to demonstrate how to apply this strategy to optimise the untraceability guarantee provided by Monero.",
}

















